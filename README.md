# ğŸš† Indian Railway Delays Data Pipeline (AWS Data Lake Project)

### ğŸ‘¤ Author: Sanket Aba Adhav  
**Role:** Data Engineer  

---

## ğŸ§  Project Overview

This project implements an **end-to-end AWS Data Lake pipeline** to process and analyze **Indian Railway train delay data** using **AWS Glue, S3, and Athena**.  

The pipeline follows the **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** and demonstrates modern cloud data engineering principles including ETL, data modeling, and serverless querying.

---

## ğŸ›ï¸ Architecture Diagram

![Architecture Diagram](docs/architecture_diagram.png)  

*Figure 1: AWS Data Lake Architecture for Train Delay Analysis.*

---

## ğŸ—‚ï¸ Data Flow Overview

| Layer | Zone | Description | Output |
|--------|------|-------------|---------|
| **Raw** | Bronze | Source CSV data from Indian Railways | `train_delays.csv` |
| **Staging** | Silver | Cleaned, standardized Parquet data | `train_delays_cleaned/` |
| **Curated** | Gold | Aggregated datasets for analytics | `avg_delay_per_train/`, `avg_delay_per_route/` |

---

## âš™ï¸ AWS Services Used

| Service | Purpose |
|----------|----------|
| **AWS S3** | Data lake storage (Raw â†’ Staging â†’ Curated) |
| **AWS Glue (PySpark)** | ETL transformation and aggregation |
| **AWS IAM** | Role-based access control for Glue and S3 |
| **AWS Glue Crawler** | Schema inference and Data Catalog registration |
| **AWS Glue Catalog** | Central metadata store for Athena |
| **AWS Athena** | Serverless SQL queries on curated data |

---

## ğŸ§© AWS Glue Jobs

### ğŸ”¹ Job 1: Raw â†’ Staging (`transform_to_staging.py`)
**Goal:** Clean and standardize raw CSV data.  
**Steps:**
- Read data from `s3://indian-railway-delays-data-pipeline-sanket/raw/train_delays.csv`
- Convert timestamps, calculate arrival/departure delays
- Derive columns: `day_of_week`, `status`, `avg_speed_kmph`
- Save as **Parquet** to:
  ```
  s3://indian-railway-delays-data-pipeline-sanket/staging/train_delays_cleaned/
  ```

---

### ğŸ”¹ Job 2: Staging â†’ Curated (`load_to_curated.py`)
**Goal:** Create analytical datasets.  
**Steps:**
- Read staging Parquet data  
- Aggregate average delays per train and per route  
- Write results to curated zone:
  ```
  s3://indian-railway-delays-data-pipeline-sanket/curated/avg_delay_per_train/
  s3://indian-railway-delays-data-pipeline-sanket/curated/avg_delay_per_route/
  ```

---

## ğŸ–‹ï¸ Glue Crawlers Configuration

| Crawler | Path | Output Database | Tables Created |
|----------|------|------------------|----------------|
| `raw_train_data_crawler` | `s3://.../raw/` | `railwaysdb` | `raw` |
| `curated_train_data_crawler` | `s3://.../curated/` | `railwaysdb` | `avg_delay_per_train`, `avg_delay_per_route` |

---

## ğŸ§® Athena Queries

Once the curated crawler registers the schema in Glue Catalog, you can query data directly in **Athena**.

```sql
-- Top 10 most delayed trains
SELECT
  train_no, train_name, avg_arrival_delay, avg_departure_delay
FROM avg_delay_per_train
ORDER BY avg_arrival_delay DESC
LIMIT 10;
```

```sql
-- Most delayed routes
SELECT
  source_station_code, destination_station_code, avg_delay_route
FROM avg_delay_per_route
ORDER BY avg_delay_route DESC
LIMIT 10;
```

---

## ğŸ“Š Athena Query Output

Below is a sample query result from the `avg_delay_per_train` table:

![Athena Output](docs/athena_output_sample.png)  
*Figure 2: Athena query showing top delayed trains from curated dataset.*

---

## ğŸ“ˆ Example Insights

| Metric | Result |
|---------|---------|
| ğŸš‰ Most Delayed Train | Rajdhani Express â€” 24.5 min delay |
| ğŸ•’ Average Delay (All Trains) | 14.2 min |
| ğŸ›ï¸ Route with Max Delay | NDLS â†’ BCT |
| ğŸ“† Worst Day | Monday |

---

## ğŸ§® Tech Stack

- **Language:** Python (PySpark)
- **Storage:** AWS S3 (Raw, Staging, Curated)
- **ETL Tool:** AWS Glue
- **Query Engine:** AWS Athena
- **Metadata Store:** AWS Glue Data Catalog
- **Permissions:** AWS IAM

---

## ğŸŒŸ Highlights

âœ… Implemented multi-zone S3 data lake (Raw, Staging, Curated)  
âœ… Created parameterized Glue ETL jobs  
âœ… Automated schema registration using Glue Crawlers  
âœ… Queried Parquet datasets via Athena  
âœ… Cloud-native & serverless data pipeline  

---

## ğŸª´ Project Folder Structure

```
indian-railway-delays-data-pipeline/
â”‚
â”œâ”€â”€ glue_jobs/
â”‚   â”œâ”€â”€ transform_to_staging.py
â”‚   â””â”€â”€ load_to_curated.py
â”‚
â”œâ”€â”€ aws_infra/
â”‚   â”œâ”€â”€ iam_roles_setup.txt
â”‚   â”œâ”€â”€ crawlers_config.md
â”‚   â”œâ”€â”€ glue_job_parameters.txt
â”‚   â””â”€â”€ bucket_structure.txt
â”‚
â”œâ”€â”€ athena_queries/
â”‚   â”œâ”€â”€ top_delayed_trains.sql
â”‚   â”œâ”€â”€ most_delayed_routes.sql
â”‚   â””â”€â”€ avg_delay_by_day.sql
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â”œâ”€â”€ athena_output_sample.png
â”‚   â””â”€â”€ project_summary.pdf
â”‚
â”œâ”€â”€ README.md
```

---

## ğŸš€ Future Enhancements

- Automate pipeline using **AWS Glue Workflows / Airflow**
- Add **data validation checks** in staging job
- Integrate with **QuickSight** for dashboards
- Schedule periodic updates via **CloudWatch Triggers**

---

## ğŸ‘¨â€ğŸ’» Author

**Sanket Aba Adhav**  
_Data Engineer | AWS & PySpark Enthusiast_  
ğŸ“§ [sankettadhav2004@gmail.com]  
ğŸ”— [LinkedIn](www.linkedin.com/in/sanket-adhav-279023257)  
ğŸ”— [GitHub](https://github.com/sanket-521/indian-railway-delays-data-pipeline)

---

> *â€œTurning raw data into reliable insights using scalable AWS data pipelines.â€*

